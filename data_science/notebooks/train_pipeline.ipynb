{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Physician Conversion Model\n",
    "\n",
    "This is a modeling pipeline for predicting whether a physician will convert to a new platform. The pipeline consists of the following steps:\n",
    "\n",
    "1. Split the data into train, validation, and inference sets.\n",
    "2. Train a variety of models without hyperparameter tuning (vanilla models).\n",
    "3. Select one of the vanilla models and tune its hyperparameters.\n",
    "4. Evaluate the model on the inference set.\n",
    "\n",
    "## Step 1: Split Data into Train, Validation, and Inference Sets\n",
    "\n",
    "The data was split into 70% train, 20% validation, and 10% inference sets. This ensures that we have enough data to train the model, validate the model, and evaluate the model on unseen data.\n",
    "\n",
    "## Step 2: Train Vanilla Models\n",
    "\n",
    "A variety of vanilla models were trained, including logistic regression, decision trees, and random forests. These models were trained without hyperparameter tuning.\n",
    "\n",
    "## Step 3: Select a Model\n",
    "\n",
    "One of the vanilla models (----) was selected for hyperparameter tuning. The hyperparameters that were tuned include the learning rate and the regularization strength.\n",
    "\n",
    "## Step 4: Evaluate the Model\n",
    "\n",
    "The tuned model was evaluated on the validation set. The model achieved a high F1-score, indicating that it is able to predict whether a physician will convert to a new platform with a high degree of accuracy.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "The modeling pipeline described in this document was able to achieve a high F1-score on the validation set. This suggests that the model is able to predict whether a physician will convert to a new platform with a high degree of accuracy.\n",
    "\n",
    "## Next Step\n",
    "\n",
    "The final/selected model will be used in Inference Pipeline to do predition on Inference set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries and Model Input Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#Visual Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Importing necessary libraries for encoding\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "\n",
    "# Importing necessary library for scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Importing necessary library for train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Importing necessary libraries for model development and evaluation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, auc\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "from hyperopt import fmin, tpe, hp, SparkTrials, STATUS_OK, Trials\n",
    "import os"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
